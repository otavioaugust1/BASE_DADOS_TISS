{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTAÇÃO ANO A ANO - CONSOLIDADAO - HOSPITALAR\n",
    "\n",
    "import pandas as pd\n",
    "import ftplib\n",
    "import os\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import time\n",
    "import ssl\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "# Criando o contexto SSL para ignorar a verificação do certificado\n",
    "context = ssl.create_default_context()\n",
    "context.check_hostname = False\n",
    "context.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "# Definindo os parâmetros de busca\n",
    "anos = ('2020', '2021')\n",
    "meses = ('01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12')\n",
    "ufs = ('AC', 'AL', 'AM', 'AP', 'BA', 'CE', 'DF', 'ES', 'GO', 'MA', 'MG', 'MS', 'MT', 'PA', 'PB', 'PE', 'PI', 'PR', 'RJ', 'RN', 'RO', 'RR', 'RS', 'SC', 'SE', 'SP', 'TO')\n",
    "\n",
    "# Definindo o diretório de trabalho\n",
    "pasta_trabalho = 'BASE DE DADOS ZIP/'\n",
    "pasta_resultado = 'BASE DE DADOS CSV/'\n",
    "\n",
    "# Criando as pastas de trabalho\n",
    "if not os.path.exists(pasta_trabalho):\n",
    "    os.makedirs(pasta_trabalho)\n",
    "\n",
    "if not os.path.exists(pasta_resultado):\n",
    "    os.makedirs(pasta_resultado)\n",
    "\n",
    "# Conectando ao servidor FTP\n",
    "ftp = ftplib.FTP('ftp.dadosabertos.ans.gov.br')\n",
    "ftp.login()\n",
    "\n",
    "# Percorrendo os parâmetros de busca\n",
    "for uf in ufs:\n",
    "    for ano in anos:\n",
    "        try:\n",
    "            dfs_meses = []\n",
    "            for mes in meses:\n",
    "                # Criando o nome do arquivo\n",
    "                nome_arquivo_zip = f'{uf}_{ano}{mes}_HOSP_CONS.zip'\n",
    "\n",
    "                # Criando o caminho local para salvar o arquivo ZIP\n",
    "                caminho_arquivo_zip = os.path.join(pasta_trabalho, nome_arquivo_zip)\n",
    "\n",
    "                # Criando a URL de download\n",
    "                url_download = f'https://ftp.dadosabertos.ans.gov.br/FTP/PDA/TISS/HOSPITALAR/{ano}/{uf}/{nome_arquivo_zip}'\n",
    "\n",
    "                # Realizando o download do arquivo ZIP\n",
    "                print(f'Baixando o arquivo: {nome_arquivo_zip}')\n",
    "                with urllib.request.urlopen(url_download, context=context) as response:\n",
    "                    with open(caminho_arquivo_zip, 'wb') as outfile:\n",
    "                        outfile.write(response.read())\n",
    "\n",
    "                # Extraindo o conteúdo do arquivo ZIP\n",
    "                print(f'Extraindo o arquivo: {nome_arquivo_zip}')\n",
    "                caminho_pasta_extracao = os.path.join(pasta_trabalho, f'{uf}_{ano}{mes}')\n",
    "                with zipfile.ZipFile(caminho_arquivo_zip, 'r') as arquivo_zip:\n",
    "                    arquivo_zip.extractall(caminho_pasta_extracao)\n",
    "\n",
    "                # Lendo o arquivo CSV\n",
    "                arquivo_csv = [arquivo for arquivo in os.listdir(caminho_pasta_extracao) if arquivo.endswith('.csv')][0]\n",
    "                df_mes = pd.read_csv(os.path.join(caminho_pasta_extracao, arquivo_csv), sep=';', encoding='latin-1')\n",
    "                dfs_meses.append(df_mes)\n",
    "\n",
    "                # Removendo os arquivos e pastas temporárias\n",
    "                os.remove(caminho_arquivo_zip)\n",
    "                caminho_arquivo_csv = os.path.join(caminho_pasta_extracao, arquivo_csv)\n",
    "                os.remove(caminho_arquivo_csv)\n",
    "                os.rmdir(caminho_pasta_extracao)\n",
    "\n",
    "            # Concatenando os dataframes dos meses\n",
    "            df_concatenado = pd.concat(dfs_meses)\n",
    "\n",
    "            # Salvando o arquivo CSV consolidado\n",
    "            caminho_arquivo_concatenado = os.path.join(pasta_resultado, f'{uf}_{ano}_HOSP_CONS.csv')\n",
    "            df_concatenado.to_csv(caminho_arquivo_concatenado, index=False)\n",
    "\n",
    "            print(f'Arquivos {uf}_{ano} processados e CSV consolidado foi salvo.')\n",
    "        except Exception as e:\n",
    "            print(f'Ocorreu um erro durante o processamento dos arquivos {uf}_{ano}: {e}')\n",
    "\n",
    "print('Processamento concluído.')\n",
    "\n",
    "# Tempo total de execução\n",
    "tempo_final = time.time()\n",
    "tempo_execucao = tempo_final - tempo_inicial\n",
    "print(f'Tempo total de execução: {tempo_execucao} segundos.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTAÇÃO ANO A ANO - DETALHADO - HOSPITALAR\n",
    "\n",
    "import pandas as pd\n",
    "import ftplib\n",
    "import os\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import time\n",
    "import ssl\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "# Criando o contexto SSL para ignorar a verificação do certificado\n",
    "context = ssl.create_default_context()\n",
    "context.check_hostname = False\n",
    "context.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "# Definindo os parâmetros de busca\n",
    "anos = ('2020', '2021')\n",
    "meses = ('01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12')\n",
    "ufs = ('AC', 'AL', 'AM', 'AP', 'BA', 'CE', 'DF', 'ES', 'GO', 'MA', 'MG', 'MS', 'MT', 'PA', 'PB', 'PE', 'PI', 'PR', 'RJ', 'RN', 'RO', 'RR', 'RS', 'SC', 'SE', 'SP', 'TO')\n",
    "\n",
    "# Definindo o diretório de trabalho\n",
    "pasta_trabalho = 'BASE DE DADOS ZIP/'\n",
    "pasta_resultado = 'BASE DE DADOS CSV/'\n",
    "\n",
    "# Criando as pastas de trabalho\n",
    "if not os.path.exists(pasta_trabalho):\n",
    "    os.makedirs(pasta_trabalho)\n",
    "\n",
    "if not os.path.exists(pasta_resultado):\n",
    "    os.makedirs(pasta_resultado)\n",
    "\n",
    "# Conectando ao servidor FTP\n",
    "ftp = ftplib.FTP('ftp.dadosabertos.ans.gov.br')\n",
    "ftp.login()\n",
    "\n",
    "# Percorrendo os parâmetros de busca\n",
    "for uf in ufs:\n",
    "    for ano in anos:\n",
    "        try:\n",
    "            dfs_meses = []\n",
    "            for mes in meses:\n",
    "                # Criando o nome do arquivo\n",
    "                nome_arquivo_zip = f'{uf}_{ano}{mes}_HOSP_DET.zip'\n",
    "\n",
    "                # Criando o caminho local para salvar o arquivo ZIP\n",
    "                caminho_arquivo_zip = os.path.join(pasta_trabalho, nome_arquivo_zip)\n",
    "\n",
    "                # Criando a URL de download\n",
    "                url_download = f'https://ftp.dadosabertos.ans.gov.br/FTP/PDA/TISS/HOSPITALAR/{ano}/{uf}/{nome_arquivo_zip}'\n",
    "\n",
    "                # Realizando o download do arquivo ZIP\n",
    "                print(f'Baixando o arquivo: {nome_arquivo_zip}')\n",
    "                with urllib.request.urlopen(url_download, context=context) as response:\n",
    "                    with open(caminho_arquivo_zip, 'wb') as outfile:\n",
    "                        outfile.write(response.read())\n",
    "\n",
    "                # Extraindo o conteúdo do arquivo ZIP\n",
    "                print(f'Extraindo o arquivo: {nome_arquivo_zip}')\n",
    "                caminho_pasta_extracao = os.path.join(pasta_trabalho, f'{uf}_{ano}{mes}')\n",
    "                with zipfile.ZipFile(caminho_arquivo_zip, 'r') as arquivo_zip:\n",
    "                    arquivo_zip.extractall(caminho_pasta_extracao)\n",
    "\n",
    "                # Lendo o arquivo CSV\n",
    "                arquivo_csv = [arquivo for arquivo in os.listdir(caminho_pasta_extracao) if arquivo.endswith('.csv')][0]\n",
    "                df_mes = pd.read_csv(os.path.join(caminho_pasta_extracao, arquivo_csv), sep=';', encoding='latin-1')\n",
    "                dfs_meses.append(df_mes)\n",
    "\n",
    "                # Removendo os arquivos e pastas temporárias\n",
    "                os.remove(caminho_arquivo_zip)\n",
    "                caminho_arquivo_csv = os.path.join(caminho_pasta_extracao, arquivo_csv)\n",
    "                os.remove(caminho_arquivo_csv)\n",
    "                os.rmdir(caminho_pasta_extracao)\n",
    "\n",
    "            # Concatenando os dataframes dos meses\n",
    "            df_concatenado = pd.concat(dfs_meses)\n",
    "\n",
    "            # Salvando o arquivo CSV consolidado\n",
    "            caminho_arquivo_concatenado = os.path.join(pasta_resultado, f'{uf}_{ano}_HOSP_DET.csv')\n",
    "            df_concatenado.to_csv(caminho_arquivo_concatenado, index=False)\n",
    "\n",
    "            print(f'Arquivos {uf}_{ano} processados e CSV consolidado foi salvo.')\n",
    "        except Exception as e:\n",
    "            print(f'Ocorreu um erro durante o processamento dos arquivos {uf}_{ano}: {e}')\n",
    "\n",
    "print('Processamento concluído.')\n",
    "\n",
    "# Tempo total de execução\n",
    "tempo_final = time.time()\n",
    "tempo_execucao = tempo_final - tempo_inicial\n",
    "print(f'Tempo total de execução: {tempo_execucao} segundos.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTAÇÃO ANO A ANO - CONSOLIDADAO - HOSPITALAR\n",
    "\n",
    "import pandas as pd\n",
    "import ftplib\n",
    "import os\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import time\n",
    "import ssl\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "# Criando o contexto SSL para ignorar a verificação do certificado\n",
    "context = ssl.create_default_context()\n",
    "context.check_hostname = False\n",
    "context.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "# Definindo os parâmetros de busca\n",
    "anos = ('2020', '2021')\n",
    "meses = ('01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12')\n",
    "ufs = ('AC', 'AL', 'AM', 'AP', 'BA', 'CE', 'DF', 'ES', 'GO', 'MA', 'MG', 'MS', 'MT', 'PA', 'PB', 'PE', 'PI', 'PR', 'RJ', 'RN', 'RO', 'RR', 'RS', 'SC', 'SE', 'SP', 'TO')\n",
    "\n",
    "# Definindo o diretório de trabalho\n",
    "pasta_trabalho = 'BASE DE DADOS ZIP/'\n",
    "pasta_resultado = 'BASE DE DADOS CSV/'\n",
    "\n",
    "# Criando as pastas de trabalho\n",
    "if not os.path.exists(pasta_trabalho):\n",
    "    os.makedirs(pasta_trabalho)\n",
    "\n",
    "if not os.path.exists(pasta_resultado):\n",
    "    os.makedirs(pasta_resultado)\n",
    "\n",
    "# Conectando ao servidor FTP\n",
    "ftp = ftplib.FTP('ftp.dadosabertos.ans.gov.br')\n",
    "ftp.login()\n",
    "\n",
    "# Percorrendo os parâmetros de busca\n",
    "for uf in ufs:\n",
    "    for ano in anos:\n",
    "        try:\n",
    "            dfs_meses = []\n",
    "            for mes in meses:\n",
    "                # Criando o nome do arquivo\n",
    "                nome_arquivo_zip = f'{uf}_{ano}{mes}_AMB_CONS.zip'\n",
    "\n",
    "                # Criando o caminho local para salvar o arquivo ZIP\n",
    "                caminho_arquivo_zip = os.path.join(pasta_trabalho, nome_arquivo_zip)\n",
    "\n",
    "                # Criando a URL de download\n",
    "                url_download = f'https://ftp.dadosabertos.ans.gov.br/FTP/PDA/TISS/AMBULATORIAL/{ano}/{uf}/{nome_arquivo_zip}'\n",
    "\n",
    "                # Realizando o download do arquivo ZIP\n",
    "                print(f'Baixando o arquivo: {nome_arquivo_zip}')\n",
    "                with urllib.request.urlopen(url_download, context=context) as response:\n",
    "                    with open(caminho_arquivo_zip, 'wb') as outfile:\n",
    "                        outfile.write(response.read())\n",
    "\n",
    "                # Extraindo o conteúdo do arquivo ZIP\n",
    "                print(f'Extraindo o arquivo: {nome_arquivo_zip}')\n",
    "                caminho_pasta_extracao = os.path.join(pasta_trabalho, f'{uf}_{ano}{mes}')\n",
    "                with zipfile.ZipFile(caminho_arquivo_zip, 'r') as arquivo_zip:\n",
    "                    arquivo_zip.extractall(caminho_pasta_extracao)\n",
    "\n",
    "                # Lendo o arquivo CSV\n",
    "                arquivo_csv = [arquivo for arquivo in os.listdir(caminho_pasta_extracao) if arquivo.endswith('.csv')][0]\n",
    "                df_mes = pd.read_csv(os.path.join(caminho_pasta_extracao, arquivo_csv), sep=';', encoding='latin-1')\n",
    "                dfs_meses.append(df_mes)\n",
    "\n",
    "                # Removendo os arquivos e pastas temporárias\n",
    "                os.remove(caminho_arquivo_zip)\n",
    "                caminho_arquivo_csv = os.path.join(caminho_pasta_extracao, arquivo_csv)\n",
    "                os.remove(caminho_arquivo_csv)\n",
    "                os.rmdir(caminho_pasta_extracao)\n",
    "\n",
    "            # Concatenando os dataframes dos meses\n",
    "            df_concatenado = pd.concat(dfs_meses)\n",
    "\n",
    "            # Salvando o arquivo CSV consolidado\n",
    "            caminho_arquivo_concatenado = os.path.join(pasta_resultado, f'{uf}_{ano}_AMB_CONS.csv')\n",
    "            df_concatenado.to_csv(caminho_arquivo_concatenado, index=False)\n",
    "\n",
    "            print(f'Arquivos {uf}_{ano} processados e CSV consolidado foi salvo.')\n",
    "        except Exception as e:\n",
    "            print(f'Ocorreu um erro durante o processamento dos arquivos {uf}_{ano}: {e}')\n",
    "\n",
    "print('Processamento concluído.')\n",
    "\n",
    "# Tempo total de execução\n",
    "tempo_final = time.time()\n",
    "tempo_execucao = tempo_final - tempo_inicial\n",
    "print(f'Tempo total de execução: {tempo_execucao} segundos.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTAÇÃO ANO A ANO - DETALHADO - HOSPITALAR\n",
    "\n",
    "import pandas as pd\n",
    "import ftplib\n",
    "import os\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import time\n",
    "import ssl\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "# Criando o contexto SSL para ignorar a verificação do certificado\n",
    "context = ssl.create_default_context()\n",
    "context.check_hostname = False\n",
    "context.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "# Definindo os parâmetros de busca\n",
    "anos = ('2020', '2021')\n",
    "meses = ('01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12')\n",
    "ufs = ('AC', 'AL', 'AM', 'AP', 'BA', 'CE', 'DF', 'ES', 'GO', 'MA', 'MG', 'MS', 'MT', 'PA', 'PB', 'PE', 'PI', 'PR', 'RJ', 'RN', 'RO', 'RR', 'RS', 'SC', 'SE', 'SP', 'TO')\n",
    "\n",
    "# Definindo o diretório de trabalho\n",
    "pasta_trabalho = 'BASE DE DADOS ZIP/'\n",
    "pasta_resultado = 'BASE DE DADOS CSV/'\n",
    "\n",
    "# Criando as pastas de trabalho\n",
    "if not os.path.exists(pasta_trabalho):\n",
    "    os.makedirs(pasta_trabalho)\n",
    "\n",
    "if not os.path.exists(pasta_resultado):\n",
    "    os.makedirs(pasta_resultado)\n",
    "\n",
    "# Conectando ao servidor FTP\n",
    "ftp = ftplib.FTP('ftp.dadosabertos.ans.gov.br')\n",
    "ftp.login()\n",
    "\n",
    "# Percorrendo os parâmetros de busca\n",
    "for uf in ufs:\n",
    "    for ano in anos:\n",
    "        try:\n",
    "            dfs_meses = []\n",
    "            for mes in meses:\n",
    "                # Criando o nome do arquivo\n",
    "                nome_arquivo_zip = f'{uf}_{ano}{mes}_AMB_DET.zip'\n",
    "\n",
    "                # Criando o caminho local para salvar o arquivo ZIP\n",
    "                caminho_arquivo_zip = os.path.join(pasta_trabalho, nome_arquivo_zip)\n",
    "\n",
    "                # Criando a URL de download\n",
    "                url_download = f'https://ftp.dadosabertos.ans.gov.br/FTP/PDA/TISS/AMBULATORIAL/{ano}/{uf}/{nome_arquivo_zip}'\n",
    "\n",
    "                # Realizando o download do arquivo ZIP\n",
    "                print(f'Baixando o arquivo: {nome_arquivo_zip}')\n",
    "                with urllib.request.urlopen(url_download, context=context) as response:\n",
    "                    with open(caminho_arquivo_zip, 'wb') as outfile:\n",
    "                        outfile.write(response.read())\n",
    "\n",
    "                # Extraindo o conteúdo do arquivo ZIP\n",
    "                print(f'Extraindo o arquivo: {nome_arquivo_zip}')\n",
    "                caminho_pasta_extracao = os.path.join(pasta_trabalho, f'{uf}_{ano}{mes}')\n",
    "                with zipfile.ZipFile(caminho_arquivo_zip, 'r') as arquivo_zip:\n",
    "                    arquivo_zip.extractall(caminho_pasta_extracao)\n",
    "\n",
    "                # Lendo o arquivo CSV\n",
    "                arquivo_csv = [arquivo for arquivo in os.listdir(caminho_pasta_extracao) if arquivo.endswith('.csv')][0]\n",
    "                df_mes = pd.read_csv(os.path.join(caminho_pasta_extracao, arquivo_csv), sep=';', encoding='latin-1')\n",
    "                dfs_meses.append(df_mes)\n",
    "\n",
    "                # Removendo os arquivos e pastas temporárias\n",
    "                os.remove(caminho_arquivo_zip)\n",
    "                caminho_arquivo_csv = os.path.join(caminho_pasta_extracao, arquivo_csv)\n",
    "                os.remove(caminho_arquivo_csv)\n",
    "                os.rmdir(caminho_pasta_extracao)\n",
    "\n",
    "            # Concatenando os dataframes dos meses\n",
    "            df_concatenado = pd.concat(dfs_meses)\n",
    "\n",
    "            # Salvando o arquivo CSV consolidado\n",
    "            caminho_arquivo_concatenado = os.path.join(pasta_resultado, f'{uf}_{ano}_AMB_DET.csv')\n",
    "            df_concatenado.to_csv(caminho_arquivo_concatenado, index=False)\n",
    "\n",
    "            print(f'Arquivos {uf}_{ano} processados e CSV consolidado foi salvo.')\n",
    "        except Exception as e:\n",
    "            print(f'Ocorreu um erro durante o processamento dos arquivos {uf}_{ano}: {e}')\n",
    "\n",
    "print('Processamento concluído.')\n",
    "\n",
    "# Tempo total de execução\n",
    "tempo_final = time.time()\n",
    "tempo_execucao = tempo_final - tempo_inicial\n",
    "print(f'Tempo total de execução: {tempo_execucao} segundos.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
